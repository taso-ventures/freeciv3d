# FreeCiv Proxy LLM Configuration
# Copy this file to .env and set your actual values

# API Tokens for LLM agent authentication (comma-separated)
LLM_API_TOKENS=your-production-token-1,your-production-token-2

# Redis configuration for distributed rate limiting (optional)
REDIS_HOST=localhost
REDIS_PORT=6379
REDIS_PASSWORD=
REDIS_DB=0
REDIS_MAX_CONNECTIONS=20
REDIS_HEALTH_CHECK_INTERVAL=30

# Security settings
SESSION_TIMEOUT_MINUTES=60
MAX_MESSAGE_SIZE_MB=1
RATE_LIMIT_ENABLED=true
MAX_CONCURRENT_SESSIONS=100

# WebSocket security
ALLOWED_ORIGINS=http://localhost:8080,https://localhost:8080,http://127.0.0.1:8080

# Cache settings
CACHE_MAX_SIZE_KB=8
CACHE_COMPRESSION_ENABLED=true
CACHE_TTL_SECONDS=5

# Cache security
CACHE_HMAC_SECRET=your-secret-key-for-cache-signing

# Session management (REQUIRED in production)
SESSION_SECRET=your-secure-session-secret-here
# Generate with: python -c 'import secrets; print(secrets.token_urlsafe(64))'

# Logging configuration
LOG_LEVEL=INFO
SECURITY_LOG_FILE=../logs/security.log

# Environment (set to 'production' in production)
ENVIRONMENT=development

# Development settings (set to false in production)
DEBUG_MODE=false
ALLOW_TEST_TOKENS=false